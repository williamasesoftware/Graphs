{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan Semilla 3.0 - Artificial Intelligence Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Space Search\n",
    "\n",
    "In this challenge you will implement some search algorithms for navigation problems.\n",
    "\n",
    "Your task is to create an autonomous vehicle that goes from point A to point B. You will be given some grid configurations that will simulate aerial images.\n",
    "\n",
    "The symbols that form the grid have a special meaning as they specify the type of the terrain and the cost to enter a grid cell with that type of terrain:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol    Meaning        Cost\n",
      "ğŸ›£        Street         1\n",
      "ğŸŒ²        Forest         10\n",
      "ğŸš¸        School street  2\n",
      "ğŸš¦        Traffic light  3\n",
      "ğŸš”        Police         4\n",
      "ğŸš˜        Traffic        6\n",
      "ğŸ›‘        Stop sign      5\n",
      "ğŸš§        Construction   7\n",
      "ğŸ¢        Buildings      15\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# symbols with meanings and costs\n",
    "print('Symbol', '   Meaning       ', 'Cost')\n",
    "print('ğŸ›£', '       Street        ', 1)\n",
    "print('ğŸŒ²', '       Forest        ', 10)\n",
    "print('ğŸš¸', '       School street ', 2)\n",
    "print('ğŸš¦', '       Traffic light ', 3)\n",
    "print('ğŸš”', '       Police        ', 4)\n",
    "print('ğŸš˜', '       Traffic       ', 6)\n",
    "print('ğŸ›‘', '       Stop sign     ', 5)\n",
    "print('ğŸš§', '       Construction  ', 7)\n",
    "print('ğŸ¢', '       Buildings     ', 15)\n",
    "\n",
    "# dictionary: Symbols with weights (costs)\n",
    "COSTS = {'ğŸ›£': 1, 'ğŸŒ²': 10, 'ğŸš¸': 2, 'ğŸš¦': 3, 'ğŸš”': 4, 'ğŸš˜': 6, 'ğŸ›‘': 5, 'ğŸš§': 7, 'ğŸ¢': 15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "test_map_1 = np.array([['ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£'],\n",
    "                       ['ğŸ›£', 'ğŸŒ²', 'ğŸŒ²', 'ğŸ›£'],\n",
    "                       ['ğŸ›£', 'ğŸŒ²', 'ğŸŒ²', 'ğŸ›£'],\n",
    "                       ['ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£'],\n",
    "                       ['ğŸŒ²', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£']])\n",
    "\n",
    "map1 = np.array([['ğŸ›£', 'ğŸš¸', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸ›‘', 'ğŸ›£', 'ğŸ›£', 'ğŸš¦', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸš”', 'ğŸ›£'],\n",
    "                 ['ğŸ›£', 'ğŸŒ²', 'ğŸŒ²', 'ğŸ›£', 'ğŸ›£', 'ğŸŒ²', 'ğŸŒ²', 'ğŸ›£', 'ğŸ›£', 'ğŸš˜', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£'],\n",
    "                 ['ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸŒ²', 'ğŸŒ²', 'ğŸ›£', 'ğŸ›£', 'ğŸš˜', 'ğŸ›£', 'ğŸŒ²', 'ğŸŒ²', 'ğŸ›£', 'ğŸš˜', 'ğŸ›£'],\n",
    "                 ['ğŸ›£', 'ğŸ›‘', 'ğŸ›£', 'ğŸš¸', 'ğŸ›£', 'ğŸŒ²', 'ğŸ›£', 'ğŸ›£', 'ğŸ¢', 'ğŸ›£', 'ğŸ›£', 'ğŸŒ²', 'ğŸŒ²', 'ğŸ›£', 'ğŸ›£', 'ğŸš¦'],\n",
    "                 ['ğŸŒ²', 'ğŸš˜', 'ğŸš˜', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸš˜', 'ğŸ›£', 'ğŸ¢', 'ğŸ›£', 'ğŸ›£', 'ğŸŒ²', 'ğŸ›£', 'ğŸ›‘', 'ğŸ›£', 'ğŸ›£'],\n",
    "                 ['ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸ¢', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸš¦', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸš¸'],\n",
    "                 ['ğŸ›£', 'ğŸ›£', 'ğŸ¢', 'ğŸ¢', 'ğŸ¢', 'ğŸ›£', 'ğŸ›‘', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸš˜', 'ğŸ›£', 'ğŸ›£', 'ğŸš¸', 'ğŸ›£', 'ğŸ›£'],\n",
    "                 ['ğŸš¦', 'ğŸ›£', 'ğŸ¢', 'ğŸš”', 'ğŸ›£', 'ğŸ›£', 'ğŸ¢', 'ğŸš§', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸš”'],\n",
    "                 ['ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸš”', 'ğŸ›£', 'ğŸ›£', 'ğŸ¢', 'ğŸ¢', 'ğŸ¢', 'ğŸš¸', 'ğŸ›£', 'ğŸ›‘', 'ğŸš˜', 'ğŸš”', 'ğŸ›£', 'ğŸ›£'],\n",
    "                 ['ğŸ›£', 'ğŸ›‘', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸ¢', 'ğŸ¢', 'ğŸ¢', 'ğŸ›£', 'ğŸ›£', 'ğŸ¢', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸš˜'],\n",
    "                 ['ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸŒ²', 'ğŸŒ²', 'ğŸš¦', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸš§', 'ğŸš˜'],\n",
    "                 ['ğŸš˜', 'ğŸš¸', 'ğŸ›£', 'ğŸŒ²', 'ğŸŒ²', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸš”', 'ğŸ›£', 'ğŸ›£', 'ğŸš¦', 'ğŸš˜', 'ğŸ›£', 'ğŸ›£'],\n",
    "                 ['ğŸš˜', 'ğŸ›£', 'ğŸš§', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸ›‘', 'ğŸ›£', 'ğŸš˜', 'ğŸš˜', 'ğŸ›£', 'ğŸš˜', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£', 'ğŸ›£']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Agent:\n",
    "\n",
    "    def __init__(self, world, costs, initial_state, goal_state):\n",
    "\n",
    "        self.moves = np.array([[0,1], [0,-1], [-1,0], [1,0]])\n",
    "        self.initial_state = initial_state\n",
    "        self.goal_state = goal_state\n",
    "        self.current_state = initial_state\n",
    "        self.world = world\n",
    "        self.costs = costs\n",
    "\n",
    "    def possible_moves(self):\n",
    "        \"\"\"\n",
    "         input: \n",
    "        \n",
    "                Current state of the world\n",
    "                Set of moves\n",
    "        \"\"\"\n",
    "\n",
    "        succ_states, succ_actions, succ_costs = [],[],[]\n",
    "\n",
    "        for move in self.moves:\n",
    "\n",
    "            # check that the next state is in the range of the world\n",
    "            #print(self.current_state)\n",
    "            if 0 <= self.current_state[0] + move[0] < self.world.shape[0] and 0 <= self.current_state[1] + move[1] < self.world.shape[1]:\n",
    "\n",
    "                # move and assign new_state to the position after moving\n",
    "                new_state = [self.current_state[0] + move[0], self.current_state[1] + move[1]]\n",
    "\n",
    "                action = [move[0], move[1]]\n",
    "\n",
    "                cost = self.costs[self.world[new_state[0], new_state[1]]]\n",
    "\n",
    "                succ_states.append(new_state)\n",
    "                succ_actions.append(action)\n",
    "                succ_costs.append(cost)\n",
    "\n",
    "        \"\"\"\n",
    "         output: \n",
    "                List of possible successor states, actions, and costs.\n",
    "        \"\"\"\n",
    "        return succ_states, succ_actions, succ_costs\n",
    "\n",
    "\n",
    "    def set_current_state(self, nex_state):\n",
    "        \n",
    "        \"\"\"\n",
    "        output:\n",
    "                new state\n",
    "        \"\"\"\n",
    "        self.current_state = nex_state\n",
    "\n",
    "\n",
    "\n",
    "class Node:\n",
    "\n",
    "    def __init__(self, state, parent=None, action=None, cost=None):\n",
    "        \"\"\"Create a search tree Node, derived from a parent by an action.\"\"\"\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.action = action\n",
    "        #self.cost = cost\n",
    "\n",
    "        self.depth = 0\n",
    "        self.path_cost = 0\n",
    "\n",
    "        if parent:\n",
    "            self.path_cost = parent.path_cost + cost\n",
    "            self.depth = parent.depth + 1\n",
    "\n",
    "\n",
    "    def successors(self, agent):\n",
    "\n",
    "        succ_states, succ_actions, succ_costs = agent.possible_moves()\n",
    "        children = []\n",
    "\n",
    "        for i in range(len(succ_states)):\n",
    "\n",
    "            children.append(Node(succ_states[i], self, succ_actions[i], succ_costs[i]))\n",
    "        return  children\n",
    "\n",
    "    def path(self):\n",
    "        \"\"\"Return a list of nodes forming the path from the root to this node.\"\"\"\n",
    "        node, path_back = self, []\n",
    "\n",
    "        # Team init\n",
    "        while node:\n",
    "            path_back.append(node)\n",
    "            node = node.parent\n",
    "        # Team final\n",
    "\n",
    "        return list(reversed(path_back))\n",
    "\n",
    "\n",
    "def depth_first_graph_search(agent):\n",
    "\n",
    "    \"\"\"\n",
    "    Search the deepest nodes in the search tree first.\n",
    "    Search through the successors of a problem to find a goal.\n",
    "    The argument frontier should be an empty queue.\n",
    "    Does not get trapped by loops.\n",
    "    If two paths reach a state, only use the first one.\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    This initializes a frontier list with a single node representing the initial state of the agent. \n",
    "    This is a stack, so nodes will be added and removed from the end of the list.\n",
    "    \"\"\"\n",
    "    frontier = [(Node(agent.initial_state))]  # Stack\n",
    "\n",
    "\n",
    "\n",
    "    # Team init\n",
    "\n",
    "\n",
    "    # This initializes an empty set to keep track of the explored states\n",
    "    explored = set()\n",
    "\n",
    "    # This starts a loop that continues until the frontier is not empty.\n",
    "    while frontier:\n",
    "\n",
    "        # This pops the last element from the frontier list, \n",
    "        # which represents the deepest unexplored node in the search tree.\n",
    "\n",
    "        node = frontier.pop()\n",
    "\n",
    "        # This checks if the state of the node is the goal state, \n",
    "        # and if so, returns the path from the initial state to the\n",
    "        # goal state using the node.path() method.\n",
    "        \n",
    "        if node.state == agent.goal_state:\n",
    "            return node.path()  # return the path to the goal node\n",
    "        \n",
    "        # This adds the state of the node to the explored set.\n",
    "        explored.add(node.state)\n",
    "        \n",
    "        # This loops through the possible successor states, \n",
    "        # actions, and costs using the agent.possible_moves() method.\n",
    "\n",
    "        for succ_state, succ_action, succ_cost in agent.possible_moves():\n",
    "            # This checks if the successor state has not been explored before.\n",
    "            if succ_state not in explored:\n",
    "                # This creates a new Node object representing the successor state, \n",
    "                # with the node as the parent, the succ_action as the action taken \n",
    "                # to reach the state, and succ_cost as the cost of the action.\n",
    "                child_node = Node(succ_state, node, succ_action, succ_cost)\n",
    "                # This adds the child_node to the end of the frontier list.\n",
    "                frontier.append(child_node)\n",
    "    # If the frontier becomes empty, the search has failed and None is returned.\n",
    "    return None\n",
    "\n",
    "    # Team final\n",
    "\n",
    "def breadth_first_graph_search(agent):\n",
    "    #TODO\n",
    "    \"\"\"\n",
    "    Search through the successors of a problem to find a goal.\n",
    "    The argument frontier should be an empty queue.\n",
    "    Does not get trapped by loops.\n",
    "    If two paths reach a state, only use the first one.\n",
    "    \"\"\"\n",
    "    frontier = [(Node(agent.initial_state))]  # Queue\n",
    "\n",
    "    explored = []\n",
    "    while frontier:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "def uniform_cost_search(agent):\n",
    "    #TODO\n",
    "    \"\"\"\n",
    "    Search the deepest nodes in the search tree first.\n",
    "    Search through the successors of a problem to find a goal.\n",
    "    The argument frontier should be an empty queue.\n",
    "    Does not get trapped by loops.\n",
    "    If two paths reach a state, only use the first one.\n",
    "    \"\"\"\n",
    "    frontier = [(Node(agent.initial_state))]  # Stack\n",
    "\n",
    "    explored = []\n",
    "    while frontier:\n",
    "        pass\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def order_frontier(frontier):\n",
    "\n",
    "    costs = []\n",
    "    new_list = []\n",
    "\n",
    "    for i in range(len(frontier)):\n",
    "\n",
    "        costs.append(frontier[i].path_cost)\n",
    "\n",
    "    costs = np.array(costs)\n",
    "\n",
    "    indexes = np.argsort(costs)\n",
    "\n",
    "    for i in range(len(frontier)):\n",
    "\n",
    "        new_list.append(frontier[indexes[i]])\n",
    "\n",
    "    return list(reversed(new_list))\n",
    "\n",
    "\n",
    "\n",
    "Ada = Agent(map1, COSTS, [0,0], [12,15])\n",
    "g_node = uniform_cost_search(Ada)\n",
    "\n",
    "print(g_node.state)\n",
    "\n",
    "p = g_node.path()\n",
    "\n",
    "moves = {'01':'â©','0-1':'âª','-10':'â«', '10':'â¬'}\n",
    "\n",
    "map_copy = map1.copy()\n",
    "\n",
    "\n",
    "for i in range(len(p)-1):\n",
    "\n",
    "    ac = p[i]\n",
    "    n = p[i+1]\n",
    "\n",
    "    map_copy[ac.state[0], ac.state[1]] = moves[str(n.action[0])+str(n.action[1])]\n",
    "\n",
    "\n",
    "for i in range(map_copy.shape[0]):\n",
    "    print(map_copy[i,:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Agent:\n",
    "\n",
    "    def __init__(self, world, costs, initial_state, goal_state):\n",
    "        \n",
    "        # Hypothesis 1\n",
    "\n",
    "        # [0,1] --> 1 UP\n",
    "        # [0,-1] --> 1 Down\n",
    "        # [-1,0] --> 1 Left\n",
    "        # [1,0] --> 1 right\n",
    "\n",
    "        # Hypothesis 2\n",
    "\n",
    "        # [0,1] --> 1 right column\n",
    "        # [0,-1] --> 1 left column\n",
    "        # [-1,0] --> 1 up row\n",
    "        # [1,0] --> 1 down row\n",
    "\n",
    "\n",
    "        self.moves = np.array([[0,1], [0,-1], [-1,0], [1,0]])\n",
    "        self.initial_state = initial_state\n",
    "        self.goal_state = goal_state\n",
    "        self.current_state = initial_state\n",
    "        self.world = world\n",
    "        self.costs = costs\n",
    "\n",
    "    def possible_moves(self):\n",
    "        \"\"\"\n",
    "         input: \n",
    "        \n",
    "                Current state of the world\n",
    "                Set of moves\n",
    "        \"\"\"\n",
    "\n",
    "        succ_states, succ_actions, succ_costs = [],[],[]\n",
    "\n",
    "        for move in self.moves:\n",
    "\n",
    "            # check that the next state is in the range of the world\n",
    "            #print(self.current_state)\n",
    "\n",
    "            # shape[0] --> rows\n",
    "            # shape[1] --> columns\n",
    "\n",
    "            # self.current_state[0] is x axis \n",
    "            # self.world.shape[0] is last row (X)\n",
    "\n",
    "            # 0 <= self.current_state[0] + move[0] < self.world.shape[0] is X boundaries\n",
    "            # 0 <= self.current_state[1] + move[1] < self.world.shape[1] is Y boundaries\n",
    "\n",
    "            if 0 <= self.current_state[0] + move[0] < self.world.shape[0] and 0 <= self.current_state[1] + move[1] < self.world.shape[1]:\n",
    "                \n",
    "\n",
    "                # move and assign new_state to the position after moving\n",
    "                new_state = [self.current_state[0] + move[0], self.current_state[1] + move[1]]\n",
    "                print(\"new_state: \",new_state)\n",
    "\n",
    "                action = [move[0], move[1]]\n",
    "                print(\"action: \",action)\n",
    "\n",
    "                cost = self.costs[self.world[new_state[0], new_state[1]]]\n",
    "                print(\"cost: \",cost)\n",
    "\n",
    "                succ_states.append(new_state)\n",
    "                succ_actions.append(action)\n",
    "                succ_costs.append(cost)\n",
    "\n",
    "        \"\"\"\n",
    "         output: \n",
    "                List of possible successor states, actions, and costs.\n",
    "        \"\"\"\n",
    "\n",
    "        return succ_states, succ_actions, succ_costs\n",
    "\n",
    "\n",
    "    def set_current_state(self, nex_state):\n",
    "        \n",
    "        \"\"\"\n",
    "        output:\n",
    "                new state\n",
    "        \"\"\"\n",
    "        self.current_state = nex_state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\ndef depth_first_graph_search(agent):\\n\\n    #Search the deepest nodes in the search tree first.\\n    #Search through the successors of a problem to find a goal.\\n    #The argument frontier should be an empty queue.\\n    #Does not get trapped by loops.\\n    #If two paths reach a state, only use the first one.\\n\\n    #This initializes a frontier list with a single node representing the initial state of the agent. \\n    #This is a stack, so nodes will be added and removed from the end of the list.\\n\\n    frontier = [(Node(agent.initial_state))]  # Stack\\n\\n    # Team init\\n\\n\\n    # This initializes an empty set to keep track of the explored states\\n    explored = []\\n\\n    # This starts a loop that continues until the frontier is not empty.\\n    while frontier:\\n\\n        # This pops the last element from the frontier list, \\n        # which represents the deepest unexplored node in the search tree.\\n\\n        node = frontier.pop()\\n\\n        # This checks if the state of the node is the goal state, \\n        # and if so, returns the path from the initial state to the\\n        # goal state using the node.path() method.\\n        \\n        if node.state == agent.goal_state:\\n            return node.path()  # return the path to the goal node\\n        \\n        # This adds the state of the node to the explored set.\\n        explored.append(node.state)\\n        \\n        # This loops through the possible successor states, \\n        # actions, and costs using the agent.possible_moves() method.\\n        succ_states, succ_actions, succ_costs = agent.possible_moves()\\n        print(succ_states)\\n        print(succ_actions)\\n        print(succ_costs)\\n\\n        for i in range(len(succ_states)):\\n            succ_state, succ_action, succ_cost= agent.possible_moves()\\n            print(succ_state[i])\\n            # This checks if the successor state has not been explored before.\\n            if not np.any(np.all(succ_state == explored, axis=0)):\\n                # This creates a new Node object representing the successor state, \\n                # with the node as the parent, the succ_action as the action taken \\n                # to reach the state, and succ_cost as the cost of the action.\\n                child_node = Node(succ_state[i], node, succ_action[i], succ_cost[i])\\n                # This adds the child_node to the end of the frontier list.\\n                frontier.append(child_node)\\n    # If the frontier becomes empty, the search has failed and None is returned.\\n    \\n    return None\\n\\n    # Team final\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class Node:\n",
    "\n",
    "    def __init__(self, state, parent=None, action=None, cost=None):\n",
    "        \"\"\"Create a search tree Node, derived from a parent by an action.\"\"\"\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.action = action\n",
    "        #self.cost = cost\n",
    "\n",
    "        self.depth = 0\n",
    "        self.path_cost = 0\n",
    "\n",
    "        if parent:\n",
    "            self.path_cost = parent.path_cost + cost\n",
    "            self.depth = parent.depth + 1\n",
    "\n",
    "\n",
    "    def successors(self, agent):\n",
    "\n",
    "        succ_states, succ_actions, succ_costs = agent.possible_moves()\n",
    "        children = []\n",
    "\n",
    "        for i in range(len(succ_states)):\n",
    "\n",
    "            children.append(Node(succ_states[i], self, succ_actions[i], succ_costs[i]))\n",
    "        return  children\n",
    "\n",
    "    def path(self):\n",
    "        \"\"\"Return a list of nodes forming the path from the root to this node.\"\"\"\n",
    "        node, path_back = self, []\n",
    "\n",
    "        # Team init\n",
    "        while node:\n",
    "            path_back.append(node)\n",
    "            node = node.parent\n",
    "        # Team final\n",
    "\n",
    "        return list(reversed(path_back))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_first_graph_search(agent):\n",
    "    \"\"\"\n",
    "    Search the deepest nodes in the search tree first.\n",
    "    Search through the successors of a problem to find a goal.\n",
    "    The argument frontier should be an empty queue.\n",
    "    Does not get trapped by loops.\n",
    "    If two paths reach a state, only use the first one.\n",
    "    \"\"\"\n",
    "    frontier = [(Node(agent.initial_state))]  # Stack\n",
    "\n",
    "    explored = []\n",
    "\n",
    "    while frontier:\n",
    "        print(frontier)\n",
    "        if len(frontier)==1:\n",
    "            print(\"frontier[0].state: \", frontier[0].state)\n",
    "            print(\"frontier[0].parent: \", frontier[0].parent)\n",
    "            print(\"frontier[0].action: \", frontier[0].action)\n",
    "            print(\"\\n\")\n",
    "        if len(frontier)==2:\n",
    "            print(\"frontier[1].state: \", frontier[1].state)\n",
    "            print(\"frontier[1].parent: \", frontier[1].parent)\n",
    "            print(\"frontier[1].action: \", frontier[1].action)\n",
    "\n",
    "        node = frontier.pop()\n",
    "\n",
    "        if node.state == agent.goal_state:\n",
    "            return node.path()\n",
    "\n",
    "        explored.append(node.state)\n",
    "\n",
    "        succ_states, succ_actions, succ_costs = agent.possible_moves()\n",
    "\n",
    "        for i in range(len(succ_states)):\n",
    "            succ_state, succ_action, succ_cost = succ_states[i], succ_actions[i], succ_costs[i]\n",
    "\n",
    "            if not np.any([np.array_equal(succ_state, state) for state in explored]):\n",
    "                child_node = Node(succ_state, node, succ_action, succ_cost)\n",
    "                frontier.append(child_node)\n",
    "        print(\"Frontier: \", frontier)\n",
    "    \n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breadth_first_graph_search(agent):\n",
    "    #TODO\n",
    "    \"\"\"\n",
    "    Search through the successors of a problem to find a goal.\n",
    "    The argument frontier should be an empty queue.\n",
    "    Does not get trapped by loops.\n",
    "    If two paths reach a state, only use the first one.\n",
    "    \"\"\"\n",
    "    frontier = [(Node(agent.initial_state))]  # Queue\n",
    "\n",
    "    explored = []\n",
    "    while frontier:\n",
    "        pass\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.Node object at 0x0000020B14B53E20>]\n",
      "frontier[0].state:  (0, 0)\n",
      "frontier[0].parent:  None\n",
      "frontier[0].action:  None\n",
      "\n",
      "\n",
      "\n",
      "New data\n",
      "\n",
      "\n",
      "self.current_state[0]:  0\n",
      "move[0]:  0\n",
      "self.world.shape[0]:  2\n",
      "self.current_state[1]:  0\n",
      "move[1]:  1\n",
      "self.world.shape[1]:  2\n",
      "move:  [0 1]\n",
      "new_state:  [0, 1]\n",
      "action:  [0, 1]\n",
      "cost:  1\n",
      "\n",
      "New data\n",
      "\n",
      "\n",
      "self.current_state[0]:  0\n",
      "move[0]:  1\n",
      "self.world.shape[0]:  2\n",
      "self.current_state[1]:  0\n",
      "move[1]:  0\n",
      "self.world.shape[1]:  2\n",
      "move:  [1 0]\n",
      "new_state:  [1, 0]\n",
      "action:  [1, 0]\n",
      "cost:  5\n",
      "parent.path_cost:  0\n",
      "cost:  1\n",
      "parent.path_cost:  0\n",
      "cost:  5\n",
      "Frontier:  [<__main__.Node object at 0x0000020B14B06A30>, <__main__.Node object at 0x0000020B05E99640>]\n",
      "[<__main__.Node object at 0x0000020B14B06A30>, <__main__.Node object at 0x0000020B05E99640>]\n",
      "frontier[1].state:  [1, 0]\n",
      "frontier[1].parent:  <__main__.Node object at 0x0000020B14B53E20>\n",
      "frontier[1].action:  [1, 0]\n",
      "\n",
      "New data\n",
      "\n",
      "\n",
      "self.current_state[0]:  0\n",
      "move[0]:  0\n",
      "self.world.shape[0]:  2\n",
      "self.current_state[1]:  0\n",
      "move[1]:  1\n",
      "self.world.shape[1]:  2\n",
      "move:  [0 1]\n",
      "new_state:  [0, 1]\n",
      "action:  [0, 1]\n",
      "cost:  1\n",
      "\n",
      "New data\n",
      "\n",
      "\n",
      "self.current_state[0]:  0\n",
      "move[0]:  1\n",
      "self.world.shape[0]:  2\n",
      "self.current_state[1]:  0\n",
      "move[1]:  0\n",
      "self.world.shape[1]:  2\n",
      "move:  [1 0]\n",
      "new_state:  [1, 0]\n",
      "action:  [1, 0]\n",
      "cost:  5\n",
      "parent.path_cost:  5\n",
      "cost:  1\n",
      "Frontier:  [<__main__.Node object at 0x0000020B14B06A30>, <__main__.Node object at 0x0000020B05E99310>]\n",
      "[<__main__.Node object at 0x0000020B14B06A30>, <__main__.Node object at 0x0000020B05E99310>]\n",
      "frontier[1].state:  [0, 1]\n",
      "frontier[1].parent:  <__main__.Node object at 0x0000020B05E99640>\n",
      "frontier[1].action:  [0, 1]\n",
      "\n",
      "New data\n",
      "\n",
      "\n",
      "self.current_state[0]:  0\n",
      "move[0]:  0\n",
      "self.world.shape[0]:  2\n",
      "self.current_state[1]:  0\n",
      "move[1]:  1\n",
      "self.world.shape[1]:  2\n",
      "move:  [0 1]\n",
      "new_state:  [0, 1]\n",
      "action:  [0, 1]\n",
      "cost:  1\n",
      "\n",
      "New data\n",
      "\n",
      "\n",
      "self.current_state[0]:  0\n",
      "move[0]:  1\n",
      "self.world.shape[0]:  2\n",
      "self.current_state[1]:  0\n",
      "move[1]:  0\n",
      "self.world.shape[1]:  2\n",
      "move:  [1 0]\n",
      "new_state:  [1, 0]\n",
      "action:  [1, 0]\n",
      "cost:  5\n",
      "Frontier:  [<__main__.Node object at 0x0000020B14B06A30>]\n",
      "[<__main__.Node object at 0x0000020B14B06A30>]\n",
      "frontier[0].state:  [0, 1]\n",
      "frontier[0].parent:  <__main__.Node object at 0x0000020B14B53E20>\n",
      "frontier[0].action:  [0, 1]\n",
      "\n",
      "\n",
      "\n",
      "New data\n",
      "\n",
      "\n",
      "self.current_state[0]:  0\n",
      "move[0]:  0\n",
      "self.world.shape[0]:  2\n",
      "self.current_state[1]:  0\n",
      "move[1]:  1\n",
      "self.world.shape[1]:  2\n",
      "move:  [0 1]\n",
      "new_state:  [0, 1]\n",
      "action:  [0, 1]\n",
      "cost:  1\n",
      "\n",
      "New data\n",
      "\n",
      "\n",
      "self.current_state[0]:  0\n",
      "move[0]:  1\n",
      "self.world.shape[0]:  2\n",
      "self.current_state[1]:  0\n",
      "move[1]:  0\n",
      "self.world.shape[1]:  2\n",
      "move:  [1 0]\n",
      "new_state:  [1, 0]\n",
      "action:  [1, 0]\n",
      "cost:  5\n",
      "Frontier:  []\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "world = np.array([[0, 1],\n",
    "                  [2, 3]])\n",
    "\n",
    "costs = {0: 10, 1: 1, 2: 5, 3:100}\n",
    "\n",
    "initial_state = (0, 0)\n",
    "goal_state = (1,1)\n",
    "\n",
    "agent1 = Agent(world, costs, initial_state, goal_state)\n",
    "\n",
    "\"\"\"\n",
    "print(agent1.world)\n",
    "print(agent1.costs)\n",
    "print(agent1.initial_state)\n",
    "print(agent1.goal_state)\n",
    "print(agent1.moves)\n",
    "print(agent1.possible_moves())\n",
    "\"\"\"\n",
    "\n",
    "path = depth_first_graph_search(agent1)\n",
    "print(path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "192px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "vscode": {
   "interpreter": {
    "hash": "5ddffc6228e7fe7cba668577e622f89d9d26445fd2ef8028a1d4f8d9a92670f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
