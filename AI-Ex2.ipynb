{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan Semilla 3.0 - Artificial Intelligence Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Space Search\n",
    "\n",
    "In this challenge you will implement some search algorithms for navigation problems.\n",
    "\n",
    "Your task is to create an autonomous vehicle that goes from point A to point B. You will be given some grid configurations that will simulate aerial images.\n",
    "\n",
    "The symbols that form the grid have a special meaning as they specify the type of the terrain and the cost to enter a grid cell with that type of terrain:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol    Meaning        Cost\n",
      "🛣        Street         1\n",
      "🌲        Forest         10\n",
      "🚸        School street  2\n",
      "🚦        Traffic light  3\n",
      "🚔        Police         4\n",
      "🚘        Traffic        6\n",
      "🛑        Stop sign      5\n",
      "🚧        Construction   7\n",
      "🏢        Buildings      15\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print('Symbol', '   Meaning       ', 'Cost')\n",
    "print('🛣', '       Street        ', 1)\n",
    "print('🌲', '       Forest        ', 10)\n",
    "print('🚸', '       School street ', 2)\n",
    "print('🚦', '       Traffic light ', 3)\n",
    "print('🚔', '       Police        ', 4)\n",
    "print('🚘', '       Traffic       ', 6)\n",
    "print('🛑', '       Stop sign     ', 5)\n",
    "print('🚧', '       Construction  ', 7)\n",
    "print('🏢', '       Buildings     ', 15)\n",
    "\n",
    "COSTS = {'🛣': 1, '🌲': 10, '🚸': 2, '🚦': 3, '🚔': 4, '🚘': 6, '🛑': 5, '🚧': 7, '🏢': 15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_map_1 = np.array([['🛣', '🛣', '🛣', '🛣'],\n",
    "                       ['🛣', '🌲', '🌲', '🛣'],\n",
    "                       ['🛣', '🌲', '🌲', '🛣'],\n",
    "                       ['🛣', '🛣', '🛣', '🛣'],\n",
    "                       ['🌲', '🛣', '🛣', '🛣']])\n",
    "\n",
    "map1 = np.array([['🛣', '🚸', '🛣', '🛣', '🛣', '🛣', '🛣', '🛑', '🛣', '🛣', '🚦', '🛣', '🛣', '🛣', '🚔', '🛣'],\n",
    "                 ['🛣', '🌲', '🌲', '🛣', '🛣', '🌲', '🌲', '🛣', '🛣', '🚘', '🛣', '🛣', '🛣', '🛣', '🛣', '🛣'],\n",
    "                 ['🛣', '🛣', '🛣', '🛣', '🛣', '🌲', '🌲', '🛣', '🛣', '🚘', '🛣', '🌲', '🌲', '🛣', '🚘', '🛣'],\n",
    "                 ['🛣', '🛑', '🛣', '🚸', '🛣', '🌲', '🛣', '🛣', '🏢', '🛣', '🛣', '🌲', '🌲', '🛣', '🛣', '🚦'],\n",
    "                 ['🌲', '🚘', '🚘', '🛣', '🛣', '🛣', '🚘', '🛣', '🏢', '🛣', '🛣', '🌲', '🛣', '🛑', '🛣', '🛣'],\n",
    "                 ['🛣', '🛣', '🛣', '🏢', '🛣', '🛣', '🛣', '🛣', '🛣', '🛣', '🚦', '🛣', '🛣', '🛣', '🛣', '🚸'],\n",
    "                 ['🛣', '🛣', '🏢', '🏢', '🏢', '🛣', '🛑', '🛣', '🛣', '🛣', '🚘', '🛣', '🛣', '🚸', '🛣', '🛣'],\n",
    "                 ['🚦', '🛣', '🏢', '🚔', '🛣', '🛣', '🏢', '🚧', '🛣', '🛣', '🛣', '🛣', '🛣', '🛣', '🛣', '🚔'],\n",
    "                 ['🛣', '🛣', '🛣', '🚔', '🛣', '🛣', '🏢', '🏢', '🏢', '🚸', '🛣', '🛑', '🚘', '🚔', '🛣', '🛣'],\n",
    "                 ['🛣', '🛑', '🛣', '🛣', '🛣', '🛣', '🏢', '🏢', '🏢', '🛣', '🛣', '🏢', '🛣', '🛣', '🛣', '🚘'],\n",
    "                 ['🛣', '🛣', '🛣', '🌲', '🌲', '🚦', '🛣', '🛣', '🛣', '🛣', '🛣', '🛣', '🛣', '🛣', '🚧', '🚘'],\n",
    "                 ['🚘', '🚸', '🛣', '🌲', '🌲', '🛣', '🛣', '🛣', '🛣', '🚔', '🛣', '🛣', '🚦', '🚘', '🛣', '🛣'],\n",
    "                 ['🚘', '🛣', '🚧', '🛣', '🛣', '🛣', '🛑', '🛣', '🚘', '🚘', '🛣', '🚘', '🛣', '🛣', '🛣', '🛣']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nAda = Agent(map1, COSTS, [0,0], [12,15])\\ng_node = uniform_cost_search(Ada)\\n\\nprint(g_node.state)\\n\\np = g_node.path()\\n\\nmoves = {'01':'⏩','0-1':'⏪','-10':'⏫', '10':'⏬'}\\n\\nmap_copy = map1.copy()\\n\\n\\nfor i in range(len(p)-1):\\n\\n    ac = p[i]\\n    n = p[i+1]\\n\\n    map_copy[ac.state[0], ac.state[1]] = moves[str(n.action[0])+str(n.action[1])]\\n\\n\\nfor i in range(map_copy.shape[0]):\\n    print(map_copy[i,:])\\n\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "class Agent:\n",
    "\n",
    "    def __init__(self, world, costs, initial_state, goal_state):\n",
    "\n",
    "        self.moves = np.array([[0,1], [0,-1], [-1,0], [1,0]])\n",
    "        self.initial_state = initial_state\n",
    "        self.goal_state = goal_state\n",
    "        self.current_state = initial_state\n",
    "        self.world = world\n",
    "        self.costs = costs\n",
    "\n",
    "    def possible_moves(self):\n",
    "\n",
    "        succ_states, succ_actions, succ_costs = [],[],[]\n",
    "\n",
    "        for move in self.moves:\n",
    "\n",
    "            # check that the next state is in the range of the world\n",
    "            #print(self.current_state)\n",
    "            if 0 <= self.current_state[0] + move[0] < self.world.shape[0] and 0 <= self.current_state[1] + move[1] < self.world.shape[1]:\n",
    "\n",
    "                # move and assign new_state to the position after moving\n",
    "                new_state = [self.current_state[0] + move[0], self.current_state[1] + move[1]]\n",
    "\n",
    "                action = [move[0], move[1]]\n",
    "\n",
    "                cost = self.costs[self.world[new_state[0], new_state[1]]]\n",
    "\n",
    "                succ_states.append(new_state)\n",
    "                succ_actions.append(action)\n",
    "                succ_costs.append(cost)\n",
    "\n",
    "        return succ_states, succ_actions, succ_costs\n",
    "\n",
    "\n",
    "    def set_current_state(self, nex_state):\n",
    "\n",
    "        self.current_state = nex_state\n",
    "\n",
    "\n",
    "\n",
    "class Node:\n",
    "\n",
    "    def __init__(self, state, parent=None, action=None, cost=None):\n",
    "        \"\"\"Create a search tree Node, derived from a parent by an action.\"\"\"\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.action = action\n",
    "        #self.cost = cost\n",
    "\n",
    "        self.depth = 0\n",
    "        self.path_cost = 0\n",
    "\n",
    "        if parent:\n",
    "            self.path_cost = parent.path_cost + cost\n",
    "            self.depth = parent.depth + 1\n",
    "\n",
    "\n",
    "    def successors(self, agent):\n",
    "\n",
    "        succ_states, succ_actions, succ_costs = agent.possible_moves()\n",
    "        children = []\n",
    "\n",
    "        for i in range(len(succ_states)):\n",
    "            agent.set_current_state(succ_states[i])\n",
    "            children.append(Node(succ_states[i], self, succ_actions[i], succ_costs[i]))\n",
    "        return  children\n",
    "\n",
    "    def path(self):\n",
    "        \"\"\"Return a list of nodes forming the path from the root to this node.\"\"\"\n",
    "        node, path_back = self, []\n",
    "        # Team init        \n",
    "        while node:\n",
    "            path_back.append(node)\n",
    "            node = node.parent \n",
    "        # Team final\n",
    "        return list(reversed(path_back))\n",
    "\n",
    "\n",
    "def depth_first_graph_search(agent):\n",
    "    \"\"\"\n",
    "    Search the deepest nodes in the search tree first.\n",
    "    Search through the successors of a problem to find a goal.\n",
    "    The argument frontier should be an empty queue.\n",
    "    Does not get trapped by loops.\n",
    "    If two paths reach a state, only use the first one.\n",
    "    \"\"\"\n",
    "    frontier = [(Node(agent.initial_state))]  # Stack\n",
    "    explored = []\n",
    "    cont=0\n",
    "    while frontier:\n",
    "        node = frontier.pop() # LIFO\n",
    "        if node.state == agent.goal_state:\n",
    "            return node.path()\n",
    "        cont=cont+1\n",
    "        if(cont==40):\n",
    "            break\n",
    "        explored.append(node)\n",
    "        print(\"\\nNode: \",node)\n",
    "        print(\"\\ninitial_state\",agent.initial_state)\n",
    "        print(\"\\nCosto: \",agent.costs)\n",
    "        print(\"\\ncurrent_state: \",node.state)\n",
    "        print(\"\\ngoal_state\",agent.goal_state)\n",
    "        agent.set_current_state(node.state)\n",
    "        #agent.current_state=node.state\n",
    "        for child in node.successors(agent):\n",
    "            if child not in explored and child not in frontier:\n",
    "                frontier.append(child)\n",
    "    return None\n",
    "\n",
    "\n",
    "def depth_first_graph_search_2(agent):\n",
    "    #TODO\n",
    "    \"\"\"\n",
    "    Search the deepest nodes in the search tree first.\n",
    "    Search through the successors of a problem to find a goal.\n",
    "    The argument frontier should be an empty queue.\n",
    "    Does not get trapped by loops.\n",
    "    If two paths reach a state, only use the first one.\n",
    "    \"\"\"\n",
    "    frontier = [(Node(agent.initial_state))]  # Stack\n",
    "\n",
    "    explored = []\n",
    "    while frontier:\n",
    "        print(\"stack:\",frontier)\n",
    "        print(\"stack reversed\",list(reversed(frontier)))\n",
    "        node=frontier.pop()    #while there's elements in the stack, pop top item and compare\n",
    "        print(\"pop stack:\",frontier)\n",
    "        agent.set_current_state(node.state)\n",
    "        print(\"agent.current_state\",agent.current_state)\n",
    "        print(\"node.state\",node.state)\n",
    "        print(\"node.parent\",node.parent)\n",
    "        print(\"node.depth\",node.depth)\n",
    "        print(\"node.action\",node.action)\n",
    "        print(\"node.path_cost\",node.path_cost)\n",
    "        if node.state==agent.goal_state:\n",
    "            return node\n",
    "        if node not in explored:\n",
    "            explored.append(node)\n",
    "        print(\"explored\",explored)\n",
    "        succesors=node.successors(agent)\n",
    "        print(\"succesors\",succesors)\n",
    "        for item in succesors:\n",
    "            if item not in explored and item not in frontier:\n",
    "                frontier.append(item)\n",
    "        print(\"stack\",frontier)\n",
    "        print(\"\\n\")\n",
    "        if node.depth>15:\n",
    "            break\n",
    "\n",
    "        \n",
    "        # print(\"succ_states\",succ_states)\n",
    "        # print(\"succ_actions\",succ_actions)\n",
    "        # print(\"succ_costs\",succ_costs)\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def breadth_first_graph_search(agent):\n",
    "    \"\"\"\n",
    "    Search through the successors of a problem to find a goal.\n",
    "    The argument frontier should be an empty queue.\n",
    "    Does not get trapped by loops.\n",
    "    If two paths reach a state, only use the first one.\n",
    "    \"\"\"\n",
    "    frontier = [Node(agent.initial_state)]  # Queue\n",
    "\n",
    "    explored = []\n",
    "    while frontier:\n",
    "        node = frontier.pop(0)\n",
    "        if node.state == agent.goal_state:\n",
    "            return node.path()\n",
    "        explored.append(node.state)\n",
    "        print(\"\\nNode: \",node)\n",
    "        print(\"\\ninitial_state\",agent.initial_state)\n",
    "        print(\"\\nCosto: \",agent.costs)\n",
    "        print(\"\\ncurrent_state: \",node.state)\n",
    "        print(\"\\ngoal_state\",agent.goal_state)\n",
    "        #agent.current_state=node.state\n",
    "        agent.set_current_state(node.state)\n",
    "        for child in node.successors(agent):\n",
    "            if child.state not in explored and child.state not in [n.state for n in frontier]:\n",
    "                frontier.append(child)\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "def uniform_cost_search(agent):\n",
    "    \"\"\"\n",
    "    Search through the successors of a problem to find a goal.\n",
    "    The argument frontier should be an empty queue.\n",
    "    Does not get trapped by loops.\n",
    "    If two paths reach a state, only use the first one.\n",
    "    \"\"\"\n",
    "    frontier = [(Node(agent.initial_state))]  # PriorityQueue\n",
    "\n",
    "    explored = []\n",
    "    while frontier:\n",
    "        node = frontier.pop(0)\n",
    "        if agent.goal_state == node.state:\n",
    "            return node.path()\n",
    "        print(\"\\nNode: \",node)\n",
    "        print(\"\\ninitial_state\",agent.initial_state)\n",
    "        print(\"\\nCosto: \",agent.costs)\n",
    "        print(\"\\ncurrent_state: \",node.state)\n",
    "        print(\"\\ngoal_state\",agent.goal_state)\n",
    "        agent.current_state=node.state\n",
    "        if node.state not in explored:\n",
    "            explored.append(node.state)\n",
    "            children = node.successors(agent)\n",
    "\n",
    "            for child in children:\n",
    "                index = 0\n",
    "                for i in range(len(frontier)):\n",
    "                    if child.path_cost < frontier[i].path_cost:\n",
    "                        index = i + 1\n",
    "                    else:\n",
    "                        break\n",
    "                frontier.insert(index, child)\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "def order_frontier(frontier):\n",
    "\n",
    "    costs = []\n",
    "    new_list = []\n",
    "\n",
    "    for i in range(len(frontier)):\n",
    "\n",
    "        costs.append(frontier[i].path_cost)\n",
    "\n",
    "    costs = np.array(costs)\n",
    "\n",
    "    indexes = np.argsort(costs)\n",
    "\n",
    "    for i in range(len(frontier)):\n",
    "\n",
    "        new_list.append(frontier[indexes[i]])\n",
    "\n",
    "    return list(reversed(new_list))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Ada = Agent(map1, COSTS, [0,0], [12,15])\n",
    "g_node = uniform_cost_search(Ada)\n",
    "\n",
    "print(g_node.state)\n",
    "\n",
    "p = g_node.path()\n",
    "\n",
    "moves = {'01':'⏩','0-1':'⏪','-10':'⏫', '10':'⏬'}\n",
    "\n",
    "map_copy = map1.copy()\n",
    "\n",
    "\n",
    "for i in range(len(p)-1):\n",
    "\n",
    "    ac = p[i]\n",
    "    n = p[i+1]\n",
    "\n",
    "    map_copy[ac.state[0], ac.state[1]] = moves[str(n.action[0])+str(n.action[1])]\n",
    "\n",
    "\n",
    "for i in range(map_copy.shape[0]):\n",
    "    print(map_copy[i,:])\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Node:  <__main__.Node object at 0x000001DC4F244F70>\n",
      "\n",
      "initial_state [0, 0]\n",
      "\n",
      "Costo:  {0: 10, 1: 1, 2: 5, 3: 100}\n",
      "\n",
      "current_state:  [0, 0]\n",
      "\n",
      "goal_state [2, 2]\n",
      "\n",
      "Node:  <__main__.Node object at 0x000001DC50AA5790>\n",
      "\n",
      "initial_state [0, 0]\n",
      "\n",
      "Costo:  {0: 10, 1: 1, 2: 5, 3: 100}\n",
      "\n",
      "current_state:  [0, 1]\n",
      "\n",
      "goal_state [2, 2]\n",
      "\n",
      "Node:  <__main__.Node object at 0x000001DC50AA57C0>\n",
      "\n",
      "initial_state [0, 0]\n",
      "\n",
      "Costo:  {0: 10, 1: 1, 2: 5, 3: 100}\n",
      "\n",
      "current_state:  [1, 0]\n",
      "\n",
      "goal_state [2, 2]\n",
      "\n",
      "Node:  <__main__.Node object at 0x000001DC50AA5040>\n",
      "\n",
      "initial_state [0, 0]\n",
      "\n",
      "Costo:  {0: 10, 1: 1, 2: 5, 3: 100}\n",
      "\n",
      "current_state:  [0, 2]\n",
      "\n",
      "goal_state [2, 2]\n",
      "\n",
      "Node:  <__main__.Node object at 0x000001DC50AA5370>\n",
      "\n",
      "initial_state [0, 0]\n",
      "\n",
      "Costo:  {0: 10, 1: 1, 2: 5, 3: 100}\n",
      "\n",
      "current_state:  [1, 1]\n",
      "\n",
      "goal_state [2, 2]\n",
      "\n",
      "Node:  <__main__.Node object at 0x000001DC50AA5400>\n",
      "\n",
      "initial_state [0, 0]\n",
      "\n",
      "Costo:  {0: 10, 1: 1, 2: 5, 3: 100}\n",
      "\n",
      "current_state:  [2, 0]\n",
      "\n",
      "goal_state [2, 2]\n",
      "\n",
      "Node:  <__main__.Node object at 0x000001DC50AA5E50>\n",
      "\n",
      "initial_state [0, 0]\n",
      "\n",
      "Costo:  {0: 10, 1: 1, 2: 5, 3: 100}\n",
      "\n",
      "current_state:  [1, 2]\n",
      "\n",
      "goal_state [2, 2]\n",
      "\n",
      "Node:  <__main__.Node object at 0x000001DC50AA59A0>\n",
      "\n",
      "initial_state [0, 0]\n",
      "\n",
      "Costo:  {0: 10, 1: 1, 2: 5, 3: 100}\n",
      "\n",
      "current_state:  [2, 1]\n",
      "\n",
      "goal_state [2, 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "world = np.array([[0, 1, 3],\n",
    "                  [2, 3, 2],\n",
    "                  [0, 1, 3]])\n",
    "\n",
    "costs = {0: 10, 1: 1, 2: 5, 3:100}\n",
    "\n",
    "initial_state = [0, 0]\n",
    "goal_state = [2,2]\n",
    "\n",
    "agent1 = Agent(world, costs, initial_state, goal_state)\n",
    "\n",
    "\"\"\"\n",
    "print(agent1.world)\n",
    "print(agent1.costs)\n",
    "print(agent1.initial_state)\n",
    "print(agent1.goal_state)\n",
    "print(agent1.moves)\n",
    "print(agent1.possible_moves())\n",
    "\"\"\"\n",
    "\n",
    "path = breadth_first_graph_search(agent1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "192px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "vscode": {
   "interpreter": {
    "hash": "112ed91ee98a6989d9d7e71eb977853a7d8456dc33f96bdb50f97ad343938d3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
